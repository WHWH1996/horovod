steps:
- label: ':docker: Build test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':docker: Build test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7'
  plugins:
  - docker-compose#v3.5.0:
      build: test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 30
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':book: Build Docs'
  command: 'cd /workdir/docs && pip install -r requirements.txt && make html'
  plugins:
  - docker#v3.1.0:
      image: 'python:3.7'
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- wait
- label: ':pytest: Run PyTests (test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2)'
  command: bash -c " cd /horovod/test && (ls -1 test_*.py | sed 's/[a-z_]*tensorflow2[a-z_.]*//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 \$(cat /mpirun_command) /bin/bash /pytest.sh mpi)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2)'
  command: bash -c " cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.standalone.xml test_spark.py test_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2)'
  command: bash -c " /etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests (test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2)'
  command: bash -c "cd /horovod/test && (ls -1 test_*.py | sed 's/[a-z_]*tensorflow2[a-z_.]*//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 horovodrun -np 2 -H localhost:2 --gloo /bin/bash /pytest.sh gloo)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2)'
  command: bash -c "cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.gloo.standalone.xml test_spark.py test_run.py test_ray.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2)'
  command: bash -c "/etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.gloo.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_6-tf1_15_0-keras2_2_4-torch1_2_0-mxnet1_4_1-pyspark2_3_2
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests (test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && (ls -1 test_*.py | sed 's/test_keras.py//g' | sed 's/test_tensorflow_keras.py//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 \$(cat /mpirun_command) /bin/bash /pytest.sh mpi)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.standalone.xml test_spark.py test_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7)'
  command: bash -c " /etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf2_0_0-keras2_2_4-torch1_3_0-mxnet1_4_1-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests (test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && (ls -1 test_*.py | sed 's/test_keras.py//g' | sed 's/test_tensorflow_keras.py//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 \$(cat /mpirun_command) /bin/bash /pytest.sh mpi)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.standalone.xml test_spark.py test_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c " /etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tf2_1_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests (test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c "cd /horovod/test && (ls -1 test_*.py | sed 's/test_keras.py//g' | sed 's/test_tensorflow_keras.py//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 horovodrun -np 2 -H localhost:2 --gloo /bin/bash /pytest.sh gloo)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c "cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.gloo.standalone.xml test_spark.py test_run.py test_ray.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c "/etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.gloo.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_7-tf2_2_0-keras2_3_1-torch1_5_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests (test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1)'
  command: bash -c "cd /horovod/test && (ls -1 test_*.py | sed 's/test_keras.py//g' | sed 's/test_tensorflow_keras.py//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 horovodrun -np 2 -H localhost:2 --gloo /bin/bash /pytest.sh gloo)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1)'
  command: bash -c "cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.gloo.standalone.xml test_spark.py test_run.py test_ray.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1)'
  command: bash -c "/etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.gloo.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-gloo-py3_8-tf2_3_0-keras2_3_1-torch1_6_0-mxnet1_5_0-pyspark3_0_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests (test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && (ls -1 test_*.py | sed 's/test_keras.py//g' | sed 's/test_tensorflow_keras.py//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 \$(cat /mpirun_command) /bin/bash /pytest.sh mpi)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.standalone.xml test_spark.py test_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7)'
  command: bash -c " /etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-openmpi-py3_6-tfhead-kerashead-torchhead-mxnethead-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests (test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && (ls -1 test_*.py | sed 's/[a-z_]*tensorflow2[a-z_.]*//g' | sed 's/test_interactiverun.py//g' | sed 's/test_spark_keras.py//g' | sed 's/test_spark_torch.py//g' | sed 's/test_spark.py//g' | sed 's/test_run.py//g' | sed 's/test_ray.py//g' | xargs -n 1 \$(cat /mpirun_command) /bin/bash /pytest.sh mpi)"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run PyTests Standalone (test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c " cd /horovod/test && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.standalone.xml test_spark.py test_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- label: ':pytest: Run Cluster PyTests (test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7)'
  command: bash -c " /etc/init.d/ssh start && cd /horovod/test/integration && pytest --forked -v --capture=fd --continue-on-collection-errors --junit-xml=/artifacts/junit.mpi.static.xml test_static_run.py"
  artifact_paths: "artifacts/**"
  plugins:
  - docker-compose#v3.5.0:
      run: test-cpu-mpich-py3_6-tf1_15_0-keras2_3_1-torch1_4_0-mxnet1_5_0-pyspark2_4_7
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 5
  retry:
    automatic: true
  agents:
    queue: cpu
- wait
